---
title: "Prototype implementation on 3cixty Nice KB"
author: "Rifat"
date: "Tuesday, October 25, 2016"
output:
  html_document: default
  pdf_document: default
---
In this implementation we presents, 3cixty Nice 2 class quality analysis report based on four quality characteristics: (i) Persistency (ii) Historical Persistency (iii) Consistency (iv) Completeness. We divided the report based on each quality characteristics. Also we presented 3cixty Nice 2 class growth analysis measure.


##Quality Problem Report Overview

###Input

In this implementation the datasets is presented in folder "~/ExperimentalData/3cixtyNice" where each class property count over 3cixtyNice 8 releases present in the CSV files. Also, the entity count of 2 classes presented in "3cixty2ClassEntityCount.csv" file. 

```{r}
location="~/ExperimentalData/3cixtyNice/"
```

The dataset presented in the folder is already processed and build in a intermediate data structure for the quality assessment approach.

To run the rmd file only need to specify the folder location for input data.

### Basic Measure Definition

(i) Persistency of a Classe is 1 if, on the KB releases (i=1....n) , En > (En-1) else Persistency = 0

Where En is the distnct entity of a class. 

(ii) Historical Persistency of a Classe is 1 if, on the KB releases (i=1....n) , Persistency = 0 else historical persistency= 0

Where En is the distnct entity of a class. 

(iii) Consistency of a predicate = 1 if frequency of a predicate fi > 100, where KB releases, i=1...n

else Consistency = 0 ,if fi < 100.

(iv) Completeness of a predicate = 1 if normalized frequency of a predicate, fi> (fi-1) ; where Time Series, i=1....n.

else Completeness = 0 

(v) For KB growth we applied a Linear regression over the KB releases (i=1....n).  

From the linear regression, We calculate the normalize distance. 

The normalized distance(ND) = (abs(Last TimeSeries Entity Count - Predicted Value)/mean(abs(Residuals))

So, KB growth is 1 if ND<1 or KB growth is 0 if ND>=1


###Results Structure

(i) Persistency: A line graph presented to visualize variation on last two 3cixty Nice Release.

(i) Historical Persistency: A table with this classes with persistency issues over the 8 Releases.

(iii) Consistency: Result of property values presented in a table. 1st table with incorrect property values and 2nd table with filtered property values

(iv) Completeness: Result of property values presented in a table with normalized property values and difference between two version of normalized property values.

(v) KB growth: A graph visualizing KB growth.

## Experiment Results

Input: Set Entity file location such as -

```{r}
location<- "/ExperimentalData/3cixtyNice/"
```

```{r,echo=FALSE,comment=NA,results='hide', message=FALSE, warning=FALSE}

library(ggplot2)
library(plyr)
library(dplyr)
library(dtplyr)
library(reshape2)
library(hts)
library('knitr')
library(reshape2)


#Input entity files
# location<- "C:/Users/rifat/Desktop/R_milan/githubRepo/KBQ/ExperimentalData/3cixtyNice/"
# 

loc<-paste(getwd(),location,sep = "")
loc<-paste(loc,"3cixty2ClassEntityCount.csv",sep = "")
entityDataSet <- read.csv(loc)


unclass=unique(entityDataSet$class)
#Implementation of consistency and completeness measures
source("helper.R")

entityWithDays= ddply(entityDataSet,.(class), here(transform), days=fn(Release))

```

### Class: lode:Event[http://linkedevents.org/ontology/Event]

Input: set file location such as -

```{r}
location<- "/ExperimentalData/3cixtyNice/"
```


```{r,echo=FALSE,comment=NA,results='hide', message=FALSE, warning=FALSE}

# location<- "C:/Users/rifat/Desktop/R_milan/githubRepo/KBQ2/ExperimentalData/3cixtyNice/lode-Event.csv"
# 
# dTproperty <- read.csv(location,header = TRUE)

loc<-paste(getwd(),location,sep = "")
loc<-paste(loc,"lode-Event.csv",sep = "")
dTproperty <- read.csv(loc,header = TRUE)

entityData=entityDataSet[entityDataSet$class==unclass[1],]

p<-persistencyPlot(entityData)

```

Entity Count for 11 Release:

```{r,echo=FALSE}
kable(entityData, format = "markdown")

shadeAreaPC(p,entityData)

```

#### Persistency

Persistency Measure Result: 

 `r entityData[nrow(entityData),3]` value  `r entityData[nrow(entityData),4]`
`r entityData[nrow(entityData)-1,3]` value  `r entityData[nrow(entityData)-1,4]`
 Persistency=  `r persistencyMeasureC(entityData)`

```{r,echo=FALSE}



```

#### Historical Persitency

```{r,echo=FALSE,comment=NA,results='hide', message=FALSE, warning=FALSE}
histPer<-histPerAllC(entityData)

```

Releases with persistency values:

```{r,echo=FALSE}
kable(histPer, format = "markdown")
```

Historical Persistency Measure Result: 

(i) Total no. of class = `r length(unclass)`
(ii) No. of persistency=`r nrow(histPer[histPer$Persistency==0,])`
(iii) HistPersistencyMeasure= `r HistPersistencyMeasureC(histPer)` %

#### Consistency

```{r,echo=FALSE}

dTproperty= ddply(dTproperty,.(Release), here(transform), NormalizedFreq=(freq/count))

#dataNormEvents=data.frame(Release=evDatPct$dep,DistinctEntity=evDatPct$distinct_entity,Predicate=evDatPct$p,freq=evDatPct$freq,evDatPctNormalizedFreq=evDatPct$normFreq)

# enEventsCor$Weight= enEvents/10000

eventsCor=dTproperty[dTproperty$NormalizedFreq<1,]

Release=unique(eventsCor$Release)

lastDep=eventsCor[eventsCor$Release==Release[length(Release)],]

prevDep=eventsCor[eventsCor$Release==Release[length(Release)-1],]

Merge=rbind(prevDep,lastDep)

```
```{r,echo=FALSE}

kable(Merge, format = "markdown")

```

#### Completeness

```{r,echo=FALSE}

Release=unique(dTproperty$Release)

lastDep=dTproperty[dTproperty$Release==Release[length(Release)],]

prevDep=dTproperty[dTproperty$Release==Release[length(Release)-1],]

Merge=merge(x=lastDep,y=prevDep,by="Property", all = TRUE)

Comp= ddply(Merge,.(Property), here(transform), freqDiff=(NormalizedFreq.x - NormalizedFreq.y))

Comp<-Comp[complete.cases(Comp),]

ConsistencyData=Comp[Comp$freqDiff<0,]

ConsistencyData<-ConsistencyData[complete.cases(ConsistencyData),]

DataSet=data.frame(Property=ConsistencyData$Property,Release20160909=ConsistencyData$NormalizedFreq.x,Release20160615=ConsistencyData$NormalizedFreq.y,NormFreqDiff=ConsistencyData$freqDiff)

DataSet<-DataSet[complete.cases(DataSet),]


```
(i) No. of incomplete properties= `r nrow(DataSet)`
(ii) List of Incomplete properties:

```{r,echo=FALSE}

kable(DataSet, format = "markdown")

```

#### KB growth 


```{r,echo=FALSE}

entity<-entityWithDays[entityWithDays$class==unclass[1],]

ND<-NormDist(entity)

graph<-plotEntity(entity)

graph

stab<-CheckND(ND)

```
The normalized distance(ND)=(abs(Last TimeSeries Value - Predicted Value)/mean(abs(Residuals))= `r ND`

KB growth is 1 if ND<1 or KB growth is 0 if ND>=1

KB growth=`r stab`



### Class: dul:Place[http://www.ontologydesignpatterns.org/ont/dul/DUL.owl#Place]

```{r,echo=FALSE,comment=NA,results='hide', message=FALSE, warning=FALSE}

# location<- "C:/Users/rifat/Desktop/R_milan/githubRepo/KBQ2/ExperimentalData/3cixtyNice/"
# 
# dTproperty <- read.csv(location,header = TRUE)

loc<-paste(getwd(),location,sep = "")
loc<-paste(loc,"dul-Place.csv",sep = "")
dTproperty <- read.csv(loc,header = TRUE)

entityData=entityDataSet[entityDataSet$class==unclass[2],]

p<-persistencyPlot(entityData)

```

Entity Count for 11 Release:

```{r,echo=FALSE}
kable(entityData, format = "markdown")
```

#### Persistency

Persistency Measure Result: 

(i) `r entityData[nrow(entityData),3]` value  `r entityData[nrow(entityData),4]`
(ii) `r entityData[nrow(entityData)-1,3]` value  `r entityData[nrow(entityData)-1,4]`
(iii) Persistency=  `r persistencyMeasureC(entityData)`

```{r,echo=FALSE}

shadeAreaPC(p,entityData)

```

#### Historical Persitency

```{r,echo=FALSE,comment=NA,results='hide', message=FALSE, warning=FALSE}
histPer<-histPerAllC(entityData)
  
```

Releases with persistency values:

```{r,echo=FALSE}
kable(histPer, format = "markdown")
```

Historical Persistency Measure Result: 

(i) Total no. of class = `r length(unclass)`
(ii) No. of persistency=`r nrow(histPer[histPer$Persistency==0,])`
(iii) HistPersistencyMeasure= `r HistPersistencyMeasureC(histPer)` %

#### Consistency

```{r,echo=FALSE}

dTproperty= ddply(dTproperty,.(Release), here(transform), NormalizedFreq=(freq/count))

#dataNormEvents=data.frame(Release=evDatPct$dep,DistinctEntity=evDatPct$distinct_entity,Predicate=evDatPct$p,freq=evDatPct$freq,evDatPctNormalizedFreq=evDatPct$normFreq)

# enEventsCor$Weight= enEvents/10000

eventsCor=dTproperty[dTproperty$NormalizedFreq<1,]

Release=unique(eventsCor$Release)

lastDep=eventsCor[eventsCor$Release==Release[length(Release)],]

prevDep=eventsCor[eventsCor$Release==Release[length(Release)-1],]

Merge=rbind(prevDep,lastDep)

```

```{r,echo=FALSE}

kable(Merge, format = "markdown")

```

#### Completeness

```{r,echo=FALSE}

Release=unique(dTproperty$Release)

lastDep=dTproperty[dTproperty$Release==Release[length(Release)],]

prevDep=dTproperty[dTproperty$Release==Release[length(Release)-1],]

Merge=merge(x=lastDep,y=prevDep,by="Property", all = TRUE)

Comp= ddply(Merge,.(Property), here(transform), freqDiff=(NormalizedFreq.x - NormalizedFreq.y))

Comp<-Comp[complete.cases(Comp),]

ConsistencyData=Comp[Comp$freqDiff<0,]

ConsistencyData<-ConsistencyData[complete.cases(ConsistencyData),]

DataSet=data.frame(Property=ConsistencyData$Property,Release20160909=ConsistencyData$NormalizedFreq.x,Release20160615=ConsistencyData$NormalizedFreq.y,NormFreqDiff=ConsistencyData$freqDiff)

DataSet<-DataSet[complete.cases(DataSet),]


```

(i) No. of incomplete properties= `r nrow(DataSet)`
(ii) List of Incomplete properties:

```{r,echo=FALSE}

kable(DataSet, format = "markdown")

```


#### KB growth 


```{r,echo=FALSE}

entity<-entityWithDays[entityWithDays$class==unclass[2],]

ND<-NormDist(entity)

graph<-plotEntity(entity)

graph

stab<-CheckND(ND)

```
The normalized distance(ND)=(abs(Last TimeSeries Value - Predicted Value)/mean(abs(Residuals))= `r ND`

KB growth is 1 if ND<1 or KB growth is 0 if ND>=1

KB growth=`r stab`
